package com.example.fruitsman.prexerk

import android.Manifest
import android.app.AlertDialog
import android.app.Dialog
import android.content.Context
import android.content.pm.PackageManager
import android.graphics.*
import android.hardware.camera2.*
import android.icu.text.CaseMap
import android.media.Image
import android.media.ImageReader
import android.media.ImageReader.OnImageAvailableListener
import androidx.appcompat.app.AppCompatActivity
import android.os.Bundle
import android.os.Handler
import android.os.HandlerThread
import android.speech.tts.TextToSpeech
import android.util.Log
import android.util.Size
import android.util.SparseIntArray
import android.view.*
import android.widget.Toast
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.fragment.app.DialogFragment
import androidx.fragment.app.Fragment
import kotlinx.android.synthetic.main.activity_ex.view.*
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit
import kotlin.math.*


class CameraActivity :
    Fragment(),
    ActivityCompat.OnRequestPermissionsResultCallback {

    /** List of body joints that should be connected.    */
    private val bodyJoints = listOf(
        Pair(BodyPart.LEFT_WRIST, BodyPart.LEFT_ELBOW),
        Pair(BodyPart.LEFT_ELBOW, BodyPart.LEFT_SHOULDER),
        Pair(BodyPart.LEFT_SHOULDER, BodyPart.RIGHT_SHOULDER),
        Pair(BodyPart.RIGHT_SHOULDER, BodyPart.RIGHT_ELBOW),
        Pair(BodyPart.RIGHT_ELBOW, BodyPart.RIGHT_WRIST),
        Pair(BodyPart.LEFT_SHOULDER, BodyPart.LEFT_HIP),
        Pair(BodyPart.LEFT_HIP, BodyPart.RIGHT_HIP),
        Pair(BodyPart.RIGHT_HIP, BodyPart.RIGHT_SHOULDER),
        Pair(BodyPart.LEFT_HIP, BodyPart.LEFT_KNEE),
        Pair(BodyPart.LEFT_KNEE, BodyPart.LEFT_ANKLE),
        Pair(BodyPart.RIGHT_HIP, BodyPart.RIGHT_KNEE),
        Pair(BodyPart.RIGHT_KNEE, BodyPart.RIGHT_ANKLE)
    )


    /** Threshold for confidence score. */
    private val minConfidence = 0.5

    /** Radius of circle used to draw keypoints.  */
    private val circleRadius = 8.0f

    /** Paint class holds the style and color information to draw geometries,text and bitmaps. */
    private var paint = Paint()

    /** A shape for extracting frame data.   */
    private val PREVIEW_WIDTH = 640
    private val PREVIEW_HEIGHT = 480

    /** An object for the Posenet library.    */
    private lateinit var posenet: Posenet

    /** ID of the current [CameraDevice].   */
    private var cameraId: String? = null

    /** A [SurfaceView] for camera preview.   */
    private var surfaceView: SurfaceView? = null

    /** A [CameraCaptureSession] for camera preview.   */
    private var captureSession: CameraCaptureSession? = null

    /** A reference to the opened [CameraDevice].    */
    private var cameraDevice: CameraDevice? = null

    /** The [android.util.Size] of camera preview.  */
    private var previewSize: Size? = null

    /** The [android.util.Size.getWidth] of camera preview. */
    private var previewWidth = 0

    /** The [android.util.Size.getHeight] of camera preview.  */
    private var previewHeight = 0

    /** A counter to keep count of total frames.  */
    private var frameCounter = 0

    /** An IntArray to save image data in ARGB8888 format  */
    private lateinit var rgbBytes: IntArray

    /** A ByteArray to save image data in YUV format  */
    private var yuvBytes = arrayOfNulls<ByteArray>(3)

    /** An additional thread for running tasks that shouldn't block the UI.   */
    private var backgroundThread: HandlerThread? = null

    /** A [Handler] for running tasks in the background.    */
    private var backgroundHandler: Handler? = null

    /** An [ImageReader] that handles preview frame capture.   */
    private var imageReader: ImageReader? = null

    /** [CaptureRequest.Builder] for the camera preview   */
    private var previewRequestBuilder: CaptureRequest.Builder? = null

    /** [CaptureRequest] generated by [.previewRequestBuilder   */
    private var previewRequest: CaptureRequest? = null

    /** A [Semaphore] to prevent the app from exiting before closing the camera.    */
    private val cameraOpenCloseLock = Semaphore(1)

    /** Whether the current camera device supports Flash or not.    */
    private var flashSupported = false

    /** Orientation of the camera sensor.   */
    private var sensorOrientation: Int? = null

    /** Abstract interface to someone holding a display surface.    */
    private var surfaceHolder: SurfaceHolder? = null

    /*
    0: unassigned
    1: camera left, head left
    2: camera left, head right (not used)
    3: camera right, head left (not used)
    4: camera right, head right
     */

    val STRAIGHT_RANGE=20;

    var heightRatio:Float=0f;
    var widthRatio:Float=0f;
    var ratio:Float=0f;

    lateinit var dataArray:IntArray
    var feedFrame:IntArray= intArrayOf(0,0,0,0,0,0,0,0);
    var accFrame:IntArray= intArrayOf(0,0,0,0,0,0,0,0);
    private var poseCode: Int=0;
    private  var currentEx:Int=1;

    private  var setC1:Int=0;
    private  var setC2:Int=0;

    private var continousFrameCounter: Int = 0;
    //counts acuurate frame

    private val MIN_CON: Int = 3;
    //minimun accurate frame continued constantly to succeed

    private val MIN_FEED: Int = 3;
    //minimun inaccurate frame continued constantly to feedback

    private val FAIL_STANDARD: Int = 2;
    //standard number

    private val MIN_ACCU: Float = 0.7f;
    //minimun accuracy compares with score

    private val gradientDifferenceRange:Float=0.2f;

    private var min_differnce: Float=0.0f;
    /** [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.   */
    private val stateCallback = object : CameraDevice.StateCallback() {

        override fun onOpened(cameraDevice: CameraDevice) {
            cameraOpenCloseLock.release()
            this@CameraActivity.cameraDevice = cameraDevice
            createCameraPreviewSession()
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            cameraOpenCloseLock.release()
            cameraDevice.close()
            this@CameraActivity.cameraDevice = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            onDisconnected(cameraDevice)
            this@CameraActivity.activity?.finish()
        }
    }

    /**
     * A [CameraCaptureSession.CaptureCallback] that handles events related to JPEG capture.
     */
    private val captureCallback = object : CameraCaptureSession.CaptureCallback() {
        override fun onCaptureProgressed(
            session: CameraCaptureSession,
            request: CaptureRequest,
            partialResult: CaptureResult
        ) {
        }

        override fun onCaptureCompleted(
            session: CameraCaptureSession,
            request: CaptureRequest,
            result: TotalCaptureResult
        ) {
        }
    }

    /**
     * Shows a [Toast] on the UI thread.
     *
     * @param text The message to show
     */
    private fun showToast(text: String) {
        val activity = activity
        activity?.runOnUiThread { Toast.makeText(activity, text, Toast.LENGTH_SHORT).show() }
    }

    override fun onCreateView(
        inflater: LayoutInflater,
        container: ViewGroup?,
        savedInstanceState: Bundle?

    ): View? = inflater.inflate(R.layout.activity_camera, container, false)

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        surfaceView = view.findViewById(R.id.surfaceView)
        surfaceHolder = surfaceView!!.holder

    }

    override fun onResume() {
        super.onResume()
        Log.d("hhhhhhhhhhhh","started")
        //Log.d("hhhhhhhh",feedFrame[0].toString())
        feedFrame= intArrayOf(0,0,0,0,0,0,0,0);
        accFrame= intArrayOf(0,0,0,0,0,0,0,0);
        currentEx=1;
        setC1=0;
        setC2=0;

        startBackgroundThread()
    }

    override fun onStart() {
        super.onStart()
        openCamera()
        posenet = Posenet(this.context!!)
    }

    override fun onPause() {
        closeCamera()
        stopBackgroundThread()
        super.onPause()
    }

    override fun onDestroy() {
        super.onDestroy()
        posenet.close()
    }

    private fun requestCameraPermission() {
        if (shouldShowRequestPermissionRationale(Manifest.permission.CAMERA)) {
            ConfirmationDialog().show(childFragmentManager, FRAGMENT_DIALOG)
        } else {
            requestPermissions(arrayOf(Manifest.permission.CAMERA), REQUEST_CAMERA_PERMISSION)
        }
    }

    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<String>,
        grantResults: IntArray
    ) {
        if (requestCode == REQUEST_CAMERA_PERMISSION) {
            if (grantResults.size != 1 || grantResults[0] != PackageManager.PERMISSION_GRANTED) {
                ErrorDialog.newInstance(getString(R.string.request_permission))
                    .show(childFragmentManager, FRAGMENT_DIALOG)
            }
        } else {
            super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        }
    }

    /**
     * Sets up member variables related to camera.
     */
    private fun setUpCameraOutputs() {

        val activity = activity
        val manager = activity!!.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            for (cameraId in manager.cameraIdList) {
                val characteristics = manager.getCameraCharacteristics(cameraId)

                // We don't use a front facing camera in this sample.
                val cameraDirection = characteristics.get(CameraCharacteristics.LENS_FACING)
                if (cameraDirection != null &&
                    cameraDirection == CameraCharacteristics.LENS_FACING_FRONT
                ) {
                    continue
                }

                previewSize = Size(PREVIEW_WIDTH, PREVIEW_HEIGHT)

                imageReader = ImageReader.newInstance(
                    PREVIEW_WIDTH, PREVIEW_HEIGHT,
                    ImageFormat.YUV_420_888, /*maxImages*/ 2
                )

                sensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)!!

                previewHeight = previewSize!!.height
                previewWidth = previewSize!!.width

                // Initialize the storage bitmaps once when the resolution is known.
                rgbBytes = IntArray(previewWidth * previewHeight)

                // Check if the flash is supported.
                flashSupported =
                    characteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE) == true

                this.cameraId = cameraId

                // We've found a viable camera and finished setting up member variables,
                // so we don't need to iterate through other available cameras.
                return
            }
        } catch (e: CameraAccessException) {
            Log.e("aaaaaaaaaa", e.toString())
        } catch (e: NullPointerException) {
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
            // device this code runs.
            ErrorDialog.newInstance(getString(R.string.camera_error))
                .show(childFragmentManager, FRAGMENT_DIALOG)
        }
    }

    /**
     * Opens the camera specified by [PosenetActivity.cameraId].
     */
    private fun openCamera() {
        val permissionCamera = ContextCompat.checkSelfPermission(activity!!, Manifest.permission.CAMERA)
        if (permissionCamera != PackageManager.PERMISSION_GRANTED) {
            requestCameraPermission()
        }
        setUpCameraOutputs()
        val manager = activity!!.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            // Wait for camera to open - 2.5 seconds is sufficient
            if (!cameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            manager.openCamera(cameraId!!, stateCallback, backgroundHandler)
        } catch (e: CameraAccessException) {
            Log.e("aaaaaaaaa", e.toString())
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }
    }

    /**
     * Closes the current [CameraDevice].
     */
    private fun closeCamera() {
        if (captureSession == null) {
            return
        }

        try {
            cameraOpenCloseLock.acquire()
            captureSession!!.close()
            captureSession = null
            cameraDevice!!.close()
            cameraDevice = null
            imageReader!!.close()
            imageReader = null
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera closing.", e)
        } finally {
            cameraOpenCloseLock.release()
        }
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread() {
        backgroundThread = HandlerThread("imageAvailableListener").also { it.start() }
        backgroundHandler = Handler(backgroundThread!!.looper)
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        backgroundThread?.quitSafely()
        try {
            backgroundThread?.join()
            backgroundThread = null
            backgroundHandler = null
        } catch (e: InterruptedException) {
            Log.e("aaaaaaaaa", e.toString())
        }
    }

    /** Fill the yuvBytes with data from image planes.   */
    private fun fillBytes(planes: Array<Image.Plane>, yuvBytes: Array<ByteArray?>) {
        // Row stride is the total number of bytes occupied in memory by a row of an image.
        // Because of the variable row stride it's not possible to know in
        // advance the actual necessary dimensions of the yuv planes.
        for (i in planes.indices) {
            val buffer = planes[i].buffer
            if (yuvBytes[i] == null) {
                yuvBytes[i] = ByteArray(buffer.capacity())
            }
            buffer.get(yuvBytes[i]!!)
        }
    }

    /** A [OnImageAvailableListener] to receive frames as they are available.  */
    private var imageAvailableListener = object : OnImageAvailableListener {
        override fun onImageAvailable(imageReader: ImageReader) {
            // We need wait until we have some size from onPreviewSizeChosen
            if (previewWidth == 0 || previewHeight == 0) {
                return
            }

            val image = imageReader.acquireLatestImage() ?: return
            fillBytes(image.planes, yuvBytes)

            ImageUtils.convertYUV420ToARGB8888(
                yuvBytes[0]!!,
                yuvBytes[1]!!,
                yuvBytes[2]!!,
                previewWidth,
                previewHeight,
                /*yRowStride=*/ image.planes[0].rowStride,
                /*uvRowStride=*/ image.planes[1].rowStride,
                /*uvPixelStride=*/ image.planes[1].pixelStride,
                rgbBytes
            )

            // Create bitmap from int array
            val imageBitmap = Bitmap.createBitmap(
                rgbBytes, previewWidth, previewHeight,
                Bitmap.Config.ARGB_8888
            )

            // Create rotated version for portrait display
            val rotateMatrix = Matrix()
            rotateMatrix.postRotate(90.0f)

            val rotatedBitmap = Bitmap.createBitmap(
                imageBitmap, 0, 0, previewWidth, previewHeight,
                rotateMatrix, true
            )
            image.close()
            // Process an image for analysis in every 2 frames.
            frameCounter = (frameCounter + 1) % 1
            if (frameCounter == 0) {
                processImage(rotatedBitmap)
            }
        }
    }

    /** Crop Bitmap to maintain aspect ratio of model input.   */
    private fun cropBitmap(bitmap: Bitmap): Bitmap {
        // Rotated bitmap has previewWidth as its height and previewHeight as width.
        val previewRatio = previewWidth.toFloat() / previewHeight
        val modelInputRatio = MODEL_HEIGHT.toFloat() / MODEL_WIDTH
        var croppedBitmap = bitmap

        // Acceptable difference between the modelInputRatio and previewRatio to skip cropping.
        val maxDifference = 1.0f.pow(-5)

        // Checks if the previewing bitmap has similar aspect ratio as the required model input.
        when {
            abs(modelInputRatio - previewRatio) < maxDifference -> return croppedBitmap
            modelInputRatio > previewRatio -> {
                // New image is taller so we are height constrained.
                val cropHeight = previewHeight - (previewWidth.toFloat() / modelInputRatio)
                croppedBitmap = Bitmap.createBitmap(
                    bitmap,
                    0,
                    (cropHeight / 2).toInt(),
                    previewHeight,
                    (previewWidth - (cropHeight / 2)).toInt()
                )
            }
            else -> {
                val cropWidth = previewWidth - (previewHeight.toFloat() * modelInputRatio)
                croppedBitmap = Bitmap.createBitmap(
                    bitmap,
                    (cropWidth / 2).toInt(),
                    0,
                    (previewHeight - (cropWidth / 2)).toInt(),
                    previewWidth
                )
            }
        }

        return croppedBitmap
    }

    /** Set the paint color and size.    */
    private fun setPaint() {
        paint.color = Color.RED
        paint.textSize = 40.0f
        paint.strokeWidth = 8.0f
    }
    /** Draw bitmap on Canvas.   */
    private fun draw(canvas: Canvas, person: Person, bitmap: Bitmap) {
        val screenWidth: Int = canvas.width
        val screenHeight: Int = canvas.height
        setPaint()
        canvas.drawBitmap(
            bitmap,
            Rect(0, 0, previewHeight, previewWidth),
            Rect(0, 0, screenWidth, screenHeight),
            paint
        )
        if(heightRatio==0f||widthRatio==0f) {
            heightRatio = screenHeight.toFloat() / MODEL_HEIGHT
            widthRatio = screenWidth.toFloat() / MODEL_WIDTH
            //ratio = widthRatio / heightRatio;
        }
        /*
        //test code
        paint.color=Color.CYAN;
        canvas.drawCircle(hX*widthRatio,hY*heightRatio,8.0f,paint);
        paint.color=Color.GRAY;
        canvas.drawCircle(fX*widthRatio,fY*heightRatio,8.0f,paint);
        paint.color=Color.RED;
        */
        // Draw key points over the image.
        var i=0;
        for (keyPoint in person.keyPoints) {
            if (keyPoint.score > minConfidence) {
                val position = keyPoint.position
                val adjustedX: Float = position.x.toFloat() * widthRatio

                val adjustedY: Float = position.y.toFloat() * heightRatio
                paint.color=Color.BLACK;
                when(i)
                {

                    /*
                    0-> paint.color=Color.BLACK;//nose
                    1-> paint.color=Color.BLUE;//leftEye
                    2-> paint.color=Color.GREEN;//rightEye
                    3-> paint.color=Color.WHITE;//leftEar
                    4->paint.color=Color.YELLOW;//rightEar
                    */
                    8->if(feedFrame[0]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[0]>=3){
                        paint.color=Color.GREEN
                    }
                    10->if(feedFrame[1]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[1]>=3){
                        paint.color=Color.GREEN
                    }
                    7->if(feedFrame[2]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[2]>=3){
                        paint.color=Color.GREEN

                    }
                    9->if(feedFrame[3]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[3]>=3){
                        paint.color=Color.GREEN

                    }
                    12->if(feedFrame[4]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[4]>=3){
                        paint.color=Color.GREEN

                    }
                    14->if(feedFrame[5]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[5]>=3){
                        paint.color=Color.GREEN

                    }
                    11->if(feedFrame[6]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[6]>=3){
                        paint.color=Color.GREEN

                    }
                    13->if(feedFrame[7]>=3){
                        paint.color=Color.RED
                    }else if(accFrame[7]>=3){
                        paint.color=Color.GREEN

                    }

                }
                canvas.drawCircle(adjustedX, adjustedY, circleRadius, paint)
                i++
            }
        }
        canvas.drawText(
            "Accuracy: "+ round(person.score*100)+"%",
            (0 * widthRatio),
            (5 * heightRatio),
            paint
        )
        /*
        canvas.drawText(
            "Score: %.2f".format(person.score),
            (1f * widthRatio),
            (257 * heightRatio),
            paint
        )
        canvas.drawText(
            "Device: %s".format(posenet.device),
            (15.0f * widthRatio),
            (243.0f * heightRatio),
            paint
        )
        canvas.drawText(
            "Time: %.2f ms".format(posenet.lastInferenceTimeNanos * 1.0f / 1_000_000),
            (15.0f * widthRatio),
            (253.0f * heightRatio),
            paint
        )
        */
        // Draw!
        surfaceHolder!!.unlockCanvasAndPost(canvas)
    }

    /** Process image using Posenet library.   */
    private fun processImage(bitmap: Bitmap) {
        // Crop bitmap.
        val croppedBitmap = cropBitmap(bitmap)

        // Created scaled version of bitmap for model input.
        val scaledBitmap = Bitmap.createScaledBitmap(croppedBitmap, MODEL_WIDTH, MODEL_HEIGHT, true)

        // Perform inference.
        val person = posenet.estimateSinglePose(scaledBitmap)
        //showBodyLocation(person);
        /*
        Log.d("yyyyyyyyyy","angle1: "+getAngle(6,8,person));
        Log.d("yyyyyyyyyy","angle2: "+getAngle(8,10,person));
        Log.d("yyyyyyyyyy","angle3: "+getAngle(5,7,person));
        Log.d("yyyyyyyyyy","angle4: "+getAngle(7,9,person));
        Log.d("yyyyyyyyyy","angle5: "+getAngle(12,14,person));
        Log.d("yyyyyyyyyy","angle6: "+getAngle(14,16,person));
        Log.d("yyyyyyyyyy","angle7: "+getAngle(11,13,person));
        Log.d("yyyyyyyyyy","angle8: "+getAngle(13,15,person));
        */
        //최소 1초 이상 유지
        val dataE: ExData = ExData.getInstance()
        if(dataE.exCode==0) {
            dataArray = intArrayOf(
                getAngle(6, 8, person),
                getAngle(8, 10, person),
                getAngle(5, 7, person),
                getAngle(7, 9, person),
                getAngle(12, 14, person),
                getAngle(14, 16, person),
                getAngle(11, 13, person),
                getAngle(13, 15, person)
            )
            for (i in 0..7) {
                if (dataE.isAccurate(dataArray[i], i)) {
                    accFrame[i]++;
                    feedFrame[i] = 0;
                } else {
                    feedFrame[i]++;
                    accFrame[i] = 0;
                }
            }
            var check: Boolean = true;
            var failedTime: Int = 0;
            var textMessage: String = "";
            for (i in 0..7) {
                if (accFrame[i] < MIN_CON) {
                    //fail
                    failedTime++;
                    if (failedTime >= FAIL_STANDARD) {
                        check = false;
                        break;
                    }
                }
            }
            (activity as ExKeepActivity).setBool(check);
            Log.d("eeeeeeeeeee","one");
            if (check) {
                //succeed
                if (((activity as ExKeepActivity).tts.isSpeaking)) {
                   // (activity as ExKeepActivity).finishTo()
                    (activity as ExKeepActivity).stopTts()
                    Log.d("eeeeeeeeeee","succceeed")
                }
                (activity as ExKeepActivity).speak(" 정확한 자세입니다")
            } else {
                //failed
                Log.d("eeeeeeeeeee","failed")
                var isFirst: Boolean = true;
                for (i in 0..7) {
                    if (feedFrame[i] >= MIN_FEED) {
                        if (isFirst) {
                            textMessage = dataE.getKFeedBack(dataArray[i], i)
                            isFirst = false;
                        } else {
                            textMessage += ("리고, " + dataE.getKFeedBack(dataArray[i], i));
                        }
                        //피드백 시 취소 feedback ->cancel
                        feedFrame[i] = 0;
                    }
                }
                if (textMessage != "") {
                    textMessage += "리세요"
                }
                if (!((activity as ExKeepActivity).tts.isSpeaking)) {
                    //Log.d("eeeeeeeeeee",textMessage);
                    (activity as ExKeepActivity).speak(textMessage)
                }
            }
            if(abs(dataArray[0])>=165&&abs(dataArray[1])>=165){
                for(i2 in 2..7){
                    if(-105<=dataArray[i2]&&dataArray[i2]<= -75){

                    }else{
                        break;
                    }
                    if(i2>=7){
                        if (((activity as ExKeepActivity).tts.isSpeaking)) {
                            (activity as ExKeepActivity).tts.stop();
                            (activity as ExKeepActivity).speak("마이크실행")
                            (activity as ExKeepActivity).promptSpeechInput();
                            break;
                        }
                    }
                }
            }
        }else if(dataE.exCode==1){

            //dynamic exercise
            val setEx1:Int=dataE.set1;
            val setEx2:Int=dataE.set2;
            val lengthEx:Int=dataE.dyLength;

            dataArray = intArrayOf(
                getAngle(6, 8, person),
                getAngle(8, 10, person),
                getAngle(5, 7, person),
                getAngle(7, 9, person),
                getAngle(12, 14, person),
                getAngle(14, 16, person),
                getAngle(11, 13, person),
                getAngle(13, 15, person)
            )//plus accuracy
            for (i in 0..7) {
                if (dataE.isAccurateD(dataArray[i], currentEx-1,i)) {
                    accFrame[i]++;
                    feedFrame[i] = 0;
                } else {
                    feedFrame[i]++;
                    accFrame[i] = 0;
                }
            }
            var check: Boolean = true;
            var failedTime: Int = 0;
            var textMessage: String = "";
            for (i in 0..7) {
                if (accFrame[i] < MIN_CON) {
                    //fail
                    failedTime++;
                    if (failedTime >= FAIL_STANDARD) {
                        check = false;
                        break;
                    }
                }
            }
            (activity as ExActivity).setBool(check);
            Log.d("eeeeeeeeeee","one");
            if (check) {
                //succeed
                Log.d("qqqqqqqqqqq","calleddddddd")
                if(currentEx>=lengthEx){
                    setC1++;
                    currentEx=1;
                    Log.d("wwwwwwwwwwwwwwwwww",(""+currentEx+"|"+setC1+" | "+setC2+" | "+setEx1+"|"+setEx2+""))
                    if(setC1>=setEx1){
                        setC2++;
                        setC1=0;
                    }
                    if(setC2>=setEx2){
                        (activity as ExActivity).finishTo()
                    }
                    (activity as ExActivity).runOnUiThread {
                        (activity as ExActivity).setSet(setC1, setC2, setEx1, setEx2)
                    }
                    //(activity as ExActivity).setSet(setC1,setC2,setEx1,setEx2)
                    //(activity as ExActivity).finishTo()
                }else {
                    currentEx++;
                }
                if (((activity as ExActivity).tts.isSpeaking)) {
                    (activity as ExActivity).stopTts()
                    Log.d("eeeeeeeeeee","succceeed")
                }
                (activity as ExActivity).speak(" 다음 자세")
            } else {
                //failed
                Log.d("eeeeeeeeeee", "failed")
                var isFirst: Boolean = true;
                for (i in 0..7) {
                    if (feedFrame[i] >= MIN_FEED) {
                        if (isFirst) {
                            textMessage = dataE.getDFeedBack(currentEx-1,i,dataArray[i])
                            isFirst = false;
                        } else {
                            textMessage += ("리고, " + dataE.getDFeedBack(currentEx-1,i,dataArray[i]))
                        }
                        //피드백 시 취소 feedback ->cancel
                        feedFrame[i] = 0;
                    }
                }
                if (textMessage != "") {
                    textMessage += "리세요"
                }
                if (!((activity as ExActivity).tts.isSpeaking)) {
                    //Log.d("eeeeeeeeeee",textMessage);
                    (activity as ExActivity).speak(textMessage)
                }
            }
            Log.d("qqqqqqqqqq","finished")
            if(abs(dataArray[0])>=165&&abs(dataArray[1])>=165){
                for(i2 in 2..7){
                    if(-105<=dataArray[i2]&&dataArray[i2]<= -75){

                    }else{
                        break;
                    }
                    if(i2>=7){
                        if (((activity as ExActivity).tts.isSpeaking)) {
                            (activity as ExActivity).tts.stop();
                            (activity as ExActivity).speak("마이크실행")
                            (activity as ExActivity).promptSpeechInput();
                            break;
                        }
                    }
                }
            }
        }
        //(activity as ExKeepActivity).speak()

        //Log.d("yyyyyyyyyy","x: "+ widthRatio*(person.keyPoints[7].position.x-person.keyPoints[10].position.x) +"y:   "+heightRatio*(person.keyPoints[10].position.y-person.keyPoints[7].position.y));
        //Log.d("yyyyyyyyyyyyy","gradient: "+getGradient(6,8,person));

        /*
        if (poseCode==0) {

            var sumHeadX: Float = 0.0f;  //sum of head x coordinate
            var sumHeadY: Float = 0.0f;  //sum of head y coordinate
            var sumFootX: Float = 0.0f;  //sum of foot x coordinate
            var sumFootY: Float = 0.0f;  //sum of foot y coordinate

            var headDataNum: Int = 0;    //number of datas
            var footDataNum: Int = 0;
            for(i in 0..16){
                Log.d("newnewnew",person.keyPoints[i].bodyPart.toString());
            }
            while (true) {
                if (person.score >= MIN_ACCU) {  //detect camera and human pose
                    continousFrameCounter++
                    if (continousFrameCounter >= MIN_CON) {
                        for (i in 0..4) {//head average
                            if (person.keyPoints[i].score >= MIN_ACCU) {
                                sumHeadX += person.keyPoints[i].position.x;
                                sumHeadY += person.keyPoints[i].position.y;
                                headDataNum++;
                            }
                        }
                        if (headDataNum == 0) {
                            continousFrameCounter = 0;
                            Log.d("rrrrrrrrrrrrrrrrrr"," head denied");
                            break;
                        }
                        for (i in 15..16) {
                            if (person.keyPoints[i].score >= MIN_ACCU) {
                                sumFootX += person.keyPoints[i].position.x;
                                sumFootY += person.keyPoints[i].position.y;
                                footDataNum++;
                            }
                        }
                        if (footDataNum == 0) {
                            continousFrameCounter = 0;
                            Log.d("rrrrrrrrrrrrrrrrrr","foot denied");
                            break;
                        }
                        val headCoordinateX: Float = sumHeadX / headDataNum;
                        val headCoordinateY: Float = sumHeadY / headDataNum;
                        val footCoordinateX: Float = sumFootX / footDataNum;
                        val footCoordinateY: Float = sumFootY / footDataNum;

                        Log.d("rrrrrrrrrrrrrrrrrr","the coordinate:            "+headCoordinateX+"   "+headCoordinateY+"     "+footCoordinateX+"       "+footCoordinateY);
                        if(headCoordinateY>footCoordinateY){ //impossible case

                        }else if(headCoordinateX>footCoordinateX)//camera left,head left
                        {
                            poseCode=1;
                        }else if(headCoordinateX<footCoordinateX)//camera right, head right
                        {
                            poseCode=4;
                        }
                        Log.d("rrrrrrrrrrrrrrrrrr","the position:                   "+poseCode);
                        break;
                    }
                } else {
                    continousFrameCounter = 0;
                }
                break;
            }
        }else if(poseCode==1||person.score>=MIN_ACCU)
        {
            Log.d("gggggggggg1",getAngle(5,11,person).toString());
            Log.d("gggggggggg2",(atan(getGradient(5,11,person))*180/PI).toString());
            Log.d("gggggggggg3",atan(ratio*(person.keyPoints[11].position.y-person.keyPoints[5].position.y
                    )/(person.keyPoints[11].position.x-person.keyPoints[5].position.x)).toString());
            Log.d("gggggggggg4",atan2(ratio*(person.keyPoints[11].position.y-person.keyPoints[5].position.y),ratio*(person.keyPoints[11].position.x-person.keyPoints[5].position.x)).toString());
            //Log.d("bbbbbbbbbbbb",((atan(getGradient(5,11,person))-atan(getGradient(11,15,person)))*180/ PI).toString());//몸 각도
            //Log.d("bbbbbbbbbbbb",((atan(getGradient(7,5,person))-atan(getGradient(5,11,person)))*180/ PI).toString());팔과 몸 각도
            Log.d("bbbbbbbbb",((atan(getGradient(9,7,person))-atan(getGradient( 7,5,person)))*180/ PI).toString());//팔 사이의 각도
            checkPosition_Straight(person);
            /*
            val i:Float=max(max(abs(getGradient(13,15,person) -getGradient(11,13,person)),
                          abs(getGradient(5,11,person)-getGradient(11,13,person))),
                          abs(getGradient(13,15,person)-getGradient(11,13,person)))

            if(min_differnce==0.0f) {
                min_differnce = abs(getGradient(5, 11, person)-getGradient(13,15,person));
                Log.d("tttttttttttttttttttt","gradient:   "+min_differnce)
            }else if(min_differnce<i)
            {
                min_differnce=i

                Log.d("ttttttttttttttttttttttt","gradient changed: " + min_differnce)
                Log.d("ttttttttttttttttttttttt","angle changed: " + atan(min_differnce)*180.0/ PI)
            }
            */
            //Log.d("qqqqqqqqqqqqqqqqqq",""+person.keyPoints[1].position.x+"     |      "+person.keyPoints[1].position.y);
            //Log.d("tttttttttttttttttttttt","angle: "+atan(getGradient(13,15,person))*180.0/ PI);
        }else if(poseCode==4||person.score>=MIN_ACCU)
        {
            Log.d("bbbbbbbbb",((atan(getGradient(9,7,person))-atan(getGradient(7,5,person)))*180/ PI).toString());

            //Log.d("rrrrrrrrrrrrrrrrrrrrrr",getGradient(4,16,person));
        }
        */
        //showBodyLocation(person)
        val canvas: Canvas = surfaceHolder!!.lockCanvas()
        draw(canvas, person, bitmap)
    }
    private fun getAb(a:Int,b:Int):Int{
        return abs(a-b)
    }
    private fun checkPosition_Straight(person:Person)
    {
        Log.d("nnnnnnnnnnnnnnn",(atan(getGradient(5,11,person))-atan(getGradient(11,15,person))*180/ PI).toString())
        if(abs(abs((atan(getGradient(5,11,person))-atan(getGradient(11,15,person)))*180/ PI)-90)<=STRAIGHT_RANGE){//correct situation
            Log.d("nnnnnnnnnn","working");
        }else{
            Log.d("nnnnnnnnnn","no working");
        }
    }
    private fun getAngle(bodyCode1: Int,bodyCode2: Int,person: Person): Int
    {
        //multiple -1 to y coordinate , since coordinate system reversed to y
        //return atan2(ratio*(person.keyPoints[bodyCode1].position.y-person.keyPoints[bodyCode2].position.y),ratio*(person.keyPoints[bodyCode2].position.x-person.keyPoints[bodyCode1].position.x))*180/PI;
        return (atan2(heightRatio*(person.keyPoints[bodyCode1].position.y-person.keyPoints[bodyCode2].position.y),widthRatio*(person.keyPoints[bodyCode2].position.x-person.keyPoints[bodyCode1].position.x))*180/PI).toInt();
    }
    private fun getGradient(bodyCode1: Int,bodyCode2: Int, person: Person):Float    //only pose 1 widthratio
    {
        return (ratio*(person.keyPoints[bodyCode2].position.y-person.keyPoints[bodyCode1].position.y)/(person.keyPoints[bodyCode2].position.x-person.keyPoints[bodyCode1].position.x).toFloat())
        //return ((person.keyPoints[bodyCode2].position.x-person.keyPoints[bodyCode1].position.x).toFloat()/(person.keyPoints[bodyCode2].position.y-person.keyPoints[bodyCode1].position.y).toFloat())
    }
    /**
     * Creates a new [CameraCaptureSession] for camera preview.
     */
    private fun showBodyLocation(person1: Person)
    {
        Log.d("aaaaaaaa",person1.score.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(0).score.toString()+" , "+person1.keyPoints.get(0).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(1).score.toString()+" , "+person1.keyPoints.get(1).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(2).score.toString()+" , "+person1.keyPoints.get(2).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(3).score.toString()+" , "+person1.keyPoints.get(3).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(4).score.toString()+" , "+person1.keyPoints.get(4).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(5).score.toString()+" , "+person1.keyPoints.get(5).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(6).score.toString()+" , "+person1.keyPoints.get(6).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(7).score.toString()+" , "+person1.keyPoints.get(7).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(8).score.toString()+" , "+person1.keyPoints.get(8).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(9).score.toString()+" , "+person1.keyPoints.get(9).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(10).score.toString()+" , "+person1.keyPoints.get(10).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(11).score.toString()+" , "+person1.keyPoints.get(11).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(12).score.toString()+" , "+person1.keyPoints.get(12).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(13).score.toString()+" , "+person1.keyPoints.get(13).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(14).score.toString()+" , "+person1.keyPoints.get(14).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(15).score.toString()+" , "+person1.keyPoints.get(15).position.y.toString());
        Log.d("wwwwwwwwwww",person1.keyPoints.get(16).score.toString()+" , "+person1.keyPoints.get(16).position.y.toString());
    }
    private fun createCameraPreviewSession() {
        try {

            // We capture images from preview in YUV format.
            imageReader = ImageReader.newInstance(
                previewSize!!.width, previewSize!!.height, ImageFormat.YUV_420_888, 2
            )
            imageReader!!.setOnImageAvailableListener(imageAvailableListener, backgroundHandler)

            // This is the surface we need to record images for processing.
            val recordingSurface = imageReader!!.surface

            // We set up a CaptureRequest.Builder with the output Surface.
            previewRequestBuilder = cameraDevice!!.createCaptureRequest(
                CameraDevice.TEMPLATE_PREVIEW
            )
            previewRequestBuilder!!.addTarget(recordingSurface)

            // Here, we create a CameraCaptureSession for camera preview.
            cameraDevice!!.createCaptureSession(
                listOf(recordingSurface),
                object : CameraCaptureSession.StateCallback() {
                    override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                        // The camera is already closed
                        if (cameraDevice == null) return

                        // When the session is ready, we start displaying the preview.
                        captureSession = cameraCaptureSession
                        try {
                            // Auto focus should be continuous for camera preview.
                            previewRequestBuilder!!.set(
                                CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE
                            )
                            // Flash is automatically enabled when necessary.
                            setAutoFlash(previewRequestBuilder!!)

                            // Finally, we start displaying the camera preview.
                            previewRequest = previewRequestBuilder!!.build()
                            captureSession!!.setRepeatingRequest(
                                previewRequest!!,
                                captureCallback, backgroundHandler
                            )
                        } catch (e: CameraAccessException) {
                            Log.e("aaaaaaaa", e.toString())
                        }
                    }

                    override fun onConfigureFailed(cameraCaptureSession: CameraCaptureSession) {
                        showToast("Failed")
                    }
                },
                null
            )
        } catch (e: CameraAccessException) {
            Log.e("aaaaaaaaaaa", e.toString())
        }
    }
    private fun setAutoFlash(requestBuilder: CaptureRequest.Builder) {
        if (flashSupported) {
            requestBuilder.set(
                CaptureRequest.CONTROL_AE_MODE,
                CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH
            )
        }
    }
    /**
     * Shows an error message dialog.
     */
    class ErrorDialog : DialogFragment() {

        override fun onCreateDialog(savedInstanceState: Bundle?): Dialog =
            AlertDialog.Builder(activity)
                .setMessage(arguments!!.getString(ARG_MESSAGE))
                .setPositiveButton(android.R.string.ok) { _, _ -> activity!!.finish() }
                .create()

        companion object {

            @JvmStatic
            private val ARG_MESSAGE = "message"

            @JvmStatic
            fun newInstance(message: String): ErrorDialog = ErrorDialog().apply {
                arguments = Bundle().apply { putString(ARG_MESSAGE, message) }
            }
        }
    }
    companion object {
        /**
         * Conversion from screen rotation to JPEG orientation.
         */
        private val ORIENTATIONS = SparseIntArray()
        private val FRAGMENT_DIALOG = "dialog"

        init {
            ORIENTATIONS.append(Surface.ROTATION_0, 90)
            ORIENTATIONS.append(Surface.ROTATION_90, 0)
            ORIENTATIONS.append(Surface.ROTATION_180, 270)
            ORIENTATIONS.append(Surface.ROTATION_270, 180)
        }
        /**
         * Tag for the [Log].
         */
    }
}